{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4)\t0.4424621378947393\n  (0, 15)\t0.697684463383976\n  (0, 3)\t0.348842231691988\n  (0, 16)\t0.4424621378947393\n  (1, 3)\t0.3574550433419527\n  (1, 14)\t0.45338639737285463\n  (1, 6)\t0.3574550433419527\n  (1, 2)\t0.45338639737285463\n  (1, 9)\t0.45338639737285463\n  (1, 5)\t0.3574550433419527\n  (2, 7)\t0.5\n  (2, 12)\t0.5\n  (2, 0)\t0.5\n  (2, 1)\t0.5\n  (3, 15)\t0.2811316284405006\n  (3, 6)\t0.2811316284405006\n  (3, 5)\t0.2811316284405006\n  (3, 13)\t0.3565798233381452\n  (3, 17)\t0.3565798233381452\n  (3, 18)\t0.3565798233381452\n  (3, 11)\t0.3565798233381452\n  (3, 8)\t0.3565798233381452\n  (3, 10)\t0.3565798233381452\n[[0.         0.         0.         0.34884223 0.44246214 0.\n  0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.69768446 0.44246214 0.\n  0.        ]\n [0.         0.         0.4533864  0.35745504 0.         0.35745504\n  0.35745504 0.         0.         0.4533864  0.         0.\n  0.         0.         0.4533864  0.         0.         0.\n  0.        ]\n [0.5        0.5        0.         0.         0.         0.\n  0.         0.5        0.         0.         0.         0.\n  0.5        0.         0.         0.         0.         0.\n  0.        ]\n [0.         0.         0.         0.         0.         0.28113163\n  0.28113163 0.         0.35657982 0.         0.35657982 0.35657982\n  0.         0.35657982 0.         0.28113163 0.         0.35657982\n  0.35657982]]\n"
     ]
    }
   ],
   "source": [
    "# TF x在当前文档中的词频\n",
    "# IDF逆文本频率，反应了一个词再所有文本中出现的频率，\n",
    "# 如果一个词在很多文本中出现，则该词的IDF值低\n",
    "\n",
    "# 方式一 \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "corpus=[\"I come to China to travel\", \n",
    "    \"This is a car polupar in China\",          \n",
    "    \"I love tea and Apple \",   \n",
    "    \"The work is to write some papers in science\"] \n",
    "vectorizer=CountVectorizer()\n",
    "transformer=TfidfTransformer()\n",
    "tfidf=transformer.fit_transform(vectorizer.fit_transform(corpus))\n",
    "# # (i,j)i代表文本的序号，j代表词的序号，第三个数字是词频\n",
    "print(tfidf)\n",
    "print(tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4)\t0.4424621378947393\n  (0, 15)\t0.697684463383976\n  (0, 3)\t0.348842231691988\n  (0, 16)\t0.4424621378947393\n  (1, 3)\t0.3574550433419527\n  (1, 14)\t0.45338639737285463\n  (1, 6)\t0.3574550433419527\n  (1, 2)\t0.45338639737285463\n  (1, 9)\t0.45338639737285463\n  (1, 5)\t0.3574550433419527\n  (2, 7)\t0.5\n  (2, 12)\t0.5\n  (2, 0)\t0.5\n  (2, 1)\t0.5\n  (3, 15)\t0.2811316284405006\n  (3, 6)\t0.2811316284405006\n  (3, 5)\t0.2811316284405006\n  (3, 13)\t0.3565798233381452\n  (3, 17)\t0.3565798233381452\n  (3, 18)\t0.3565798233381452\n  (3, 11)\t0.3565798233381452\n  (3, 8)\t0.3565798233381452\n  (3, 10)\t0.3565798233381452\n"
     ]
    }
   ],
   "source": [
    "# 方式二\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf2=TfidfVectorizer()\n",
    "repr=tfidf2.fit_transform(corpus)\n",
    "print(repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
