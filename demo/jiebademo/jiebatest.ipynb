{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.588 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Mode:我/来到/北京/清华/清华大学/华大/大学\nDefault Mode:我/来到/北京/清华大学\n他, 来到, 了, 网易, 杭研, 大厦\n小明, 硕士, 毕业, 于, 中国, 科学, 学院, 科学院, 中国科学院, 计算, 计算所, ，, 后, 在, 日本, 京都, 大学, 日本京都大学, 深造\ncut for Search 李小福/是/创新/办/主任/也/是/计算/云计算/方面/的/专家/;/ /什么/是/八/一双/鹿/\n/例如/我/输入/一个/带/“/韩玉/赏鉴/”/的/标题/，/在/自定/定义/自定义/自定义词/库中/也/增加/了/此/词为/N/类/\n/「/台/中/」/正確/應該/不會/被/切開/。/mac/上/可/分出/「/石墨/烯/」/；/此時/又/可以/分出/來凱/特琳/了/。\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "test_sent = (\n",
    "\"李小福是创新办主任也是云计算方面的专家; 什么是八一双鹿\\n\"\n",
    "\"例如我输入一个带“韩玉赏鉴”的标题，在自定义词库中也增加了此词为N类\\n\"\n",
    "\"「台中」正確應該不會被切開。mac上可分出「石墨烯」；此時又可以分出來凱特琳了。\"\n",
    ")\n",
    "# 全模式\n",
    "seg_list=jieba.cut(\"我来到北京清华大学\",cut_all=True)\n",
    "print(\"Full Mode:\"+\"/\".join(seg_list))\n",
    "# 精确模式\n",
    "seg_list=jieba.cut(\"我来到北京清华大学\",cut_all=False)\n",
    "print(\"Default Mode:\"+'/'.join(seg_list))\n",
    "seg_list = jieba.cut(\"他来到了网易杭研大厦\")  # 默认是精确模式\n",
    "print(\", \".join(seg_list))\n",
    "\n",
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  # 搜索引擎模式\n",
    "print(\", \".join(seg_list))\n",
    "# jieba.add_word()可以增加分词的准确性\n",
    "jieba.add_word('云计算')\n",
    "seg_list = jieba.cut_for_search(test_sent) # 搜索引擎模式\n",
    "print (\"cut for Search\",\"/\".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['李小福', '是', '创新', '办', '主任', '也', '是', '云计算', '方面', '的', '专家']\n李小福 是 创新 办 主任 也 是 云计算 方面 的 专家\n李小福 是 创新 办 主任 也 是 计算 云计算 方面 的 专家\n"
     ]
    }
   ],
   "source": [
    "result_lcut=jieba.lcut(\"李小福是创新办主任也是云计算方面的专家\")\n",
    "print(result_lcut)\n",
    "print(\" \".join(result_lcut))\n",
    "print(\" \".join(jieba.lcut_for_search(\"李小福是创新办主任也是云计算方面的专家\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小明 硕士 毕业 于 中国科学院 计算所\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(jieba.cut('小明硕士毕业于中国科学院计算所')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "小明 硕士 毕业于 中国科学院 计算所\n"
     ]
    }
   ],
   "source": [
    "jieba.suggest_freq('毕业于',True)\n",
    "print(\" \".join(jieba.cut('小明硕士毕业于中国科学院计算所')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.593 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "韦少 杜兰特 全明星 全明星赛 MVP 威少 正赛 科尔 投篮 勇士 球员 斯布鲁克 更衣柜 三连庄 NBA 张卫平 西部 指导 雷霆 明星队\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse as analyse\n",
    "lines=open('./demo/data/NBA.txt').read()\n",
    "print(\" \".join(analyse.extract_tags(lines,topK=20,\n",
    "                                    withWeight=False,allowPOS=())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我爱你 l\n中国 ns\n"
     ]
    }
   ],
   "source": [
    "# https://www.biaodianfu.com/pos-tagging-set.html 词性标注\n",
    "import jieba.posseg as pseg\n",
    "words=pseg.cut(\"我爱你中国\")\n",
    "for word,flag in words:\n",
    "    print('%s %s'%(word,flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是默认模式的tokenize\n自然语言\t\t start: 0 \t\t end:4\n处理\t\t start: 4 \t\t end:6\n非常\t\t start: 6 \t\t end:8\n有用\t\t start: 8 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "from jieba import tokenize\n",
    "print('这是默认模式的tokenize')\n",
    "result=tokenize(u'自然语言处理非常有用')\n",
    "for tk in result:\n",
    "    print(\"%s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n-----------我是神奇的分割线------------\n\n这是搜索模式的tokenize\n自然\t\t start: 0 \t\t end:2\n语言\t\t start: 2 \t\t end:4\n自然语言\t\t start: 0 \t\t end:4\n处理\t\t start: 4 \t\t end:6\n非常\t\t start: 6 \t\t end:8\n有用\t\t start: 8 \t\t end:10\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n-----------我是神奇的分割线------------\\n\")\n",
    "\n",
    "print (\"这是搜索模式的tokenize\")\n",
    "result = tokenize(u'自然语言处理非常有用', mode='search')\n",
    "for tk in result:\n",
    "    print(\"%s\\t\\t start: %d \\t\\t end:%d\" % (tk[0],tk[1],tk[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
